[{"content":"\u003cp\u003eData visualization can be defined as the use of graphical or pictorial\nrepresentations to present data in a way that makes it easier to\nunderstand, analyze, and communicate. It involves the use of visual\nelements such as charts, graphs, and maps to help users better\nunderstand and interpret complex data sets. Data visualization is an\nimportant tool for exploratory data analysis, as well as for\ncommunicating results to others. By presenting data in a visual format,\ndata visualization can also help to reveal new connections and insights\nthat might not be apparent from a purely numerical or textual analysis.\nEffective data visualization allows viewers to quickly identify\npatterns, trends, and relationships within the data, and can be used to\nhighlight key insights or communicate complex ideas. In this project, I\nwill explain the details that need to be considered when plotting with\nbase R \u003ccode\u003egraphics\u003c/code\u003e.\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003eIn base R, there are many functions that can be used to create different\ntypes of plots.Although there is no clear distinction between high-level\nand low-level functions, I like to divide functions as such. I believe\nthat there are some functions which can be called as high-level plotting\nfunctions tend to provide a convenient way to create a specific type of\nplot with a relatively small amount of code. On the other hand, there\nare some functions which can be called as low-level plotting functions\nprovide more control and flexibility, but require more coding to create\na plot. At this point, it needs to be noted that the package \u003ccode\u003eggplot2\u003c/code\u003e,\nwhich will be explained later in another project, is built around the\nconcept of \u0026ldquo;grammar of graphics\u0026rdquo;, which means that it provides a set of\nrules for building plots by combining basic building blocks or\ncomponents. It is possible to think low-level functions as components in\nthe \u003ccode\u003eggplot2\u003c/code\u003e package.\u003c/p\u003e\n\u003cp\u003eThere are five high-level plotting functions in the base R. There\nfunctions can be listed as follows:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca href=\"https://www.rdocumentation.org/packages/graphics/versions/3.6.2/topics/barplot\"\u003ebarplot()\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca href=\"https://www.rdocumentation.org/packages/graphics/versions/3.6.2/topics/pie\"\u003epie()\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca href=\"https://www.rdocumentation.org/packages/graphics/versions/3.6.2/topics/hist\"\u003ehist()\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca href=\"https://www.rdocumentation.org/packages/graphics/versions/3.6.2/topics/boxplot\"\u003eboxplot()\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca href=\"https://www.rdocumentation.org/packages/graphics/versions/3.6.2/topics/plot\"\u003eplot()\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eThere are seven low-level plotting functions in the base R. There\nfunctions can be listed as follows:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca href=\"https://www.rdocumentation.org/packages/graphics/versions/3.6.2/topics/text\"\u003etext()\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca href=\"https://www.rdocumentation.org/packages/graphics/versions/3.6.2/topics/points\"\u003epoints()\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca href=\"https://www.rdocumentation.org/packages/graphics/versions/3.6.2/topics/lines\"\u003elines()\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca href=\"https://www.rdocumentation.org/packages/graphics/versions/3.6.2/topics/legend\"\u003elegend()\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca href=\"https://www.rdocumentation.org/packages/graphics/versions/3.6.2/topics/abline\"\u003eabline()\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca href=\"https://www.rdocumentation.org/packages/graphics/versions/3.6.2/topics/arrows\"\u003earrows()\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca href=\"https://www.rdocumentation.org/packages/graphics/versions/3.6.2/topics/symbols\"\u003esymbols()\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eI think there is one thing that should be mentioned at this point.\nHigh-level plotting functions can create a plot by themselves, while\nlow-level plotting functions must have a high-level function in order to\nwork. While showing each high-level function, I tried to explain the\nworking logic of these two types of functions by adding one or more\nlow-level functions.\u003c/p\u003e\n\u003chr\u003e\n\u003ch3 id=\"barplot\"\u003eBarplot\u003c/h3\u003e\n\u003cp\u003eBarplot is used to create bar charts, which are a type of graph that\ndisplays categorical data as rectangular bars with heights or lengths\nproportional to the values they represent. By looking at the relative\nheights or lengths of the bars, it might be possible to quickly compare\nthe values and identify any trends or patterns. The barplot() function\nin base R has several arguments that can be used to customize the\nappearance and behavior of the resulting bar chart.\u003c/p\u003e\n\u003cp\u003eHere are some of the most commonly used arguments of the barplot()\nfunction:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cem\u003eheight \u0026mdash; a vector or matrix of values that represent the heights\nof the bars. This argument is required.\u003c/em\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cem\u003enames.arg \u0026mdash; a vector of names or labels for the bars. The length\nof this vector should be equal to the length of the height vector.\u003c/em\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cem\u003ecol \u0026mdash; a vector of colors for the bars. The length of this vector\nshould be equal to the length of the height vector.\u003c/em\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cem\u003eborder \u0026mdash; the color of the borders of the bars. The default value\nis \u0026ldquo;black\u0026rdquo;.\u003c/em\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cem\u003emain \u0026mdash; a main title for the plot.\u003c/em\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cem\u003exlab \u0026mdash; a label for the x-axis.\u003c/em\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cem\u003eylab \u0026mdash; a label for the y-axis.\u003c/em\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cem\u003elegend.text \u0026mdash; a vector of labels for the legend.\u003c/em\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cem\u003eargs.legend \u0026mdash; a list of arguments to control the appearance of\nthe legend.\u003c/em\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cem\u003ewidth \u0026mdash; the width of the bars. The default value is 0.5.\u003c/em\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cem\u003espace \u0026mdash; the amount of space between the bars. The default value\nis 1.\u003c/em\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cem\u003ehoriz \u0026mdash; a logical value that controls the orientation of the\nbars. If TRUE, the bars are horizontal; if FALSE, they are vertical.\nThe default value is FALSE.\u003c/em\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cem\u003edensity \u0026mdash; the density of shading lines in the bars. The default\nvalue is 1.\u003c/em\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cem\u003eangle \u0026mdash; the angle of shading lines in the bars. The default value\nis 45.\u003c/em\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eLets create a vector for barplot examples:\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003eset.seed(111)\nx1 \u0026lt;- sample(LETTERS[1:5], size = 20, rep= T)\nlet \u0026lt;- table(x1)\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eBasic barplot with required arguments look like the following:\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ebarplot(let)\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cimg src=\"https://cdn-images-1.medium.com/max/800/1*RXlHL2TlERcoG70oAPHV6A.jpeg\" alt=\"basicbarplot\"\u003e\u003c/p\u003e\n\u003cp\u003eHere how it looks like if I add some of the arguments:\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ebarplot(let, main = \u0026#34;Title of the plot\u0026#34;,  \n        xlab = \u0026#34;X axis\u0026#34;, \n        ylab = \u0026#34;Y axis\u0026#34;, \n        horiz = T, \n        col = c(\u0026#34;red\u0026#34;, \u0026#34;blue\u0026#34;, \u0026#34;gray1\u0026#34;, \u0026#34;navy\u0026#34;, \u0026#34;gold\u0026#34;), # assigns colors by order\n        xlim = c(0,7), # limit values of the x axis\n        legend.text = c(\u0026#34;Group 1\u0026#34;, \u0026#34;Group 2\u0026#34;, \u0026#34;Group 3\u0026#34;, \u0026#34;Group 4\u0026#34;, \u0026#34;Group 5\u0026#34;)) # adds legends by order\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cimg src=\"https://cdn-images-1.medium.com/v2/resize:fit:800/1*Vj5EFT8XHg27jV8mnpDuRw.jpeg\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eAdvantages:\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eBar plots are an effective way to represent categorical data as they\nallow easy visualization of the data.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eBar plots are intuitive and easy to understand, even for individuals\nwho are not familiar with the data.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThey allow for easy comparison of data across different categories\nor groups.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eBar plots can be used to display many different types of data,\nincluding frequency distributions, percentages, and counts.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThey can be customized by changing the colors, labels, and\norientation of the bars to make them more visually appealing.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eDisadvantages:\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eBar plots are only useful for categorical data and may not be\nappropriate for continuous data.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eIf there are too many categories, the plot may become too cluttered\nto read easily.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eIf the scale of the y-axis is not appropriate, the bars can be\nmisleading and give the impression that the differences between the\ndata points are greater or smaller than they actually are.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eIf the bars are too wide or too close together, differences between\nthe data points may be obscured, making it difficult to accurately\ncompare the data.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eBar plots may not be the best choice for displaying complex data,\nand other visualization methods may be more appropriate.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4 id=\"stacked-barplot\"\u003e\u003cstrong\u003eStacked Barplot\u003c/strong\u003e\u003c/h4\u003e\n\u003cp\u003eA stacked bar plot is a type of bar chart that displays multiple\nvariables by stacking them on top of each other. Each bar in the chart\nrepresents a category, and the height or length of the bar represents\nthe total value of the variables being stacked. The stacked bar plot\nbreaks down the total value of each category into different segments,\nwith each segment representing a different variable.\u003c/p\u003e\n\u003cp\u003eHere how stacked barplot looks like:\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ebarplot(let2, xlab = \u0026#34;X axis\u0026#34;,\n        ylab = \u0026#34;Y axis\u0026#34;, \n        col = c(\u0026#34;red\u0026#34;, \u0026#34;blue\u0026#34;, \u0026#34;gray1\u0026#34;, \u0026#34;navy\u0026#34;, \u0026#34;gold\u0026#34;),\n        legend.text = rownames(let2),\n        xlim = c(0,3))\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cimg src=\"https://cdn-images-1.medium.com/v2/resize:fit:800/1*UTjFy0ixRud8ZzYxiXOCtw.jpeg\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003eA clustered barplot, also known as a \u003cem\u003egrouped barplot\u003c/em\u003e, is a type of bar\nchart that displays multiple variables for each category by grouping\nthem together. In a clustered barplot, each category has multiple bars,\none for each variable being displayed, and the bars for each variable\nare grouped together side by side.\u003c/p\u003e\n\u003cp\u003eHere how clustered barplot looks like:\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ebarplot(let2, xlab = \u0026#34;X axis\u0026#34;, \n        ylab = \u0026#34;Y axis\u0026#34;, \n        col = c(\u0026#34;red\u0026#34;, \u0026#34;blue\u0026#34;, \u0026#34;gray1\u0026#34;, \u0026#34;navy\u0026#34;, \u0026#34;gold\u0026#34;),\n        legend.text = rownames(let2),\n        xlim = c(0,14),\n        beside = T # for clustered barplot\n) \n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cimg src=\"https://cdn-images-1.medium.com/v2/resize:fit:800/1*Bn4t9mVHFh64SDwKUvYdOw.jpeg\" alt=\"\"\u003e\u003c/p\u003e\n\u003ch4 id=\"clustered-barplotbarplot-with-a-low-level-functiontext\"\u003e\u003cstrong\u003eClustered Barplotbarplot() with a low-level function text()\u003c/strong\u003e\u003c/h4\u003e\n\u003cp\u003eFor this example, I will use \u003ccode\u003equakes\u003c/code\u003e dataset from\u003ccode\u003edatasets\u003c/code\u003e package in\nR. At first, I will set the bin widths with \u003ccode\u003eseq\u003c/code\u003e function. Then, I will\nchoose the limits to cut values with \u003ccode\u003ecut\u003c/code\u003e function. Lastly, I will use\n\u003ccode\u003etable\u003c/code\u003e function to prepare it for the barplot() function and it will\nlook like the follows in a basic form:\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003eb \u0026lt;- seq(4,6.5, by=0.5) # setting bin widths\n\nc \u0026lt;- cut(quakes$mag, breaks = b, right = F) # where to cut the values\n\nt \u0026lt;- table(c)\n\n# this is how it looks like in a basic form\nbarplot(t)\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cimg src=\"https://cdn-images-1.medium.com/v2/resize:fit:800/1*OfoLDJNJjNyXKN6xWXnQjA.jpeg\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003eLets rock this!\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ebarplot(t, main = \u0026#34;earthquake counts by magnitude\u0026#34;, xlab = \u0026#34;madnitude\u0026#34;, \n        ylab = \u0026#34;Frequency\u0026#34;,\n        col = \u0026#34;chocolate\u0026#34;,\n        border = \u0026#34;khaki1\u0026#34;,\n        ylim = c(0,500))\ntext(0.7, 400,t[1])\ntext(1.85,450,t[2])\ntext(3.15,185,t[3])\ntext(4.25,55,t[4])\ntext(5.5,30,t[5])\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cimg src=\"https://cdn-images-1.medium.com/v2/resize:fit:800/1*zWy8eQWieuEAiqFaT3c7qg.jpeg\" alt=\"\"\u003e\u003c/p\u003e\n\u003ch3 id=\"pie-chart\"\u003ePie Chart\u003c/h3\u003e\n\u003cp\u003eA pie chart is a type of circular graph that is commonly used to\nrepresent data as a set of slices, where each slice corresponds to a\ncategory and its area or angle represents the proportion of that\ncategory relative to the whole. The total area or angle of the pie\nrepresents the total value of the data being displayed. The \u003ccode\u003epie()\u003c/code\u003e\nfunction in R is used to create a pie chart.\u003c/p\u003e\n\u003cp\u003eHere are some of the most commonly used arguments of pie() function:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cem\u003ex: A vector of non-negative numeric values that specifies the data\nto be represented in the pie chart.\u003c/em\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cem\u003elabels: A character vector of labels to be used for each slice of\nthe pie chart.\u003c/em\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cem\u003emain: A title for the pie chart.\u003c/em\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cem\u003ecol: A vector of colors to be used for each slice of the pie\nchart.\u003c/em\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cem\u003eborder: A color to be used for the border of each slice of the pie\nchart.\u003c/em\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cem\u003elty: The line type to be used for the border of each slice of the\npie chart.\u003c/em\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cem\u003einit.angle: The starting angle in degrees for the first slice of\nthe pie chart.\u003c/em\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cem\u003eclockwise: A logical value that specifies whether the slices of the\npie chart should be drawn clockwise or counterclockwise.\u003c/em\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cem\u003edensity: A value that specifies the density of shading lines for\neach slice of the pie chart.\u003c/em\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cem\u003eangle: A vector of angles in degrees to be used for shading each\nslice of the pie chart.\u003c/em\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eI will again create a vector to draw a pie chart. You can follow the\ncodes below:\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003eset.seed(111)\nx1 \u0026lt;- sample(LETTERS[1:5], size = 20, rep = T)  \nlet \u0026lt;- table(x1)\n\nr1 \u0026lt;- (let/length(x1))\n\nl1 \u0026lt;- paste(\u0026#34;Group-\u0026#34;, names(let) , sep= \u0026#34; \u0026#34; , r1*100, \u0026#34;%\u0026#34;)\n\n# basic pie() looks like the following:\npie(let, labels = l1, \n    main = \u0026#34;Title\u0026#34;,\n    col = c(\u0026#34;red\u0026#34;, \u0026#34;blue\u0026#34;, \u0026#34;gray2\u0026#34;, \u0026#34;navy\u0026#34;, \u0026#34;gold\u0026#34;)\n)\n\u003c/code\u003e\u003c/pre\u003e\u003chr\u003e\n\u003cp\u003ePie charts have several advantages and disadvantages. Some of these\ninclude:\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eAdvantages:\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003ePie charts are easy to understand and interpret, making them a\npopular choice for displaying data.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThey allow for easy comparison of proportions or percentages across\ndifferent categories.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003ePie charts have an attractive design that can make data more\nappealing and engaging.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003ePie charts are efficient in terms of space and can display a large\namount of data in a small area.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThey are best used to display one set of data where the categories\ndo not have any overlapping.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eDisadvantages:\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003ePie charts can be difficult to compare accurately, particularly if\nthe slices are small or if there are many categories.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThey can be misleading if the slices are not drawn to scale or if\nthe angles are not accurate.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003ePie charts may not be the best choice for displaying complex data,\nand other visualization methods may be more appropriate.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003ePie charts are not ideal for displaying large amounts of data or\ndata with many categories.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThey are limited to displaying proportions and do not show absolute\nvalues or counts.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch3 id=\"histogram\"\u003eHistogram\u003c/h3\u003e\n\u003cp\u003eA histogram is a graphical representation of the distribution of a\ndataset. It is a type of bar plot that represents the frequency or count\nof values that fall within a set of intervals or \u0026ldquo;bins\u0026rdquo;. The x-axis\nrepresents the intervals or bins of values, while the y-axis represents\nthe frequency or count of values that fall within each interval. Bin\nwidth is an important detail that has been widely studied in the\nliterature and is still debated. This is because deciding the number and\nwidth of the bins in a histogram can have a significant impact on the\nresulting visualization. Lets look at the significance of the bins with\nbasic histograms. I will use \u003ccode\u003empg\u003c/code\u003e variable from the \u003ccode\u003emtcars\u003c/code\u003e dataset.\nHere how histogram looks like with default bin width which is Sturges'\nformula.\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003empg \u0026lt;- mtcars$mpgr\nhist(mpg)\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cimg src=\"https://cdn-images-1.medium.com/max/800/1*ME3iAXvrVIVYgMyoa0rBPw.jpeg\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003eIf I change breaks as follows, it will look like:\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ehist(mpg, breaks = 2)\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eAssuming that I wanted to analyse this histogram to have an idea about\nthe distribution of the mpg variable, I would have different ideas about\nthe distribution of the mpg variable for both graphs. For this reason,\nthere are several methods for determining the appropriate number of\nbins, rules can be applied to \u003ccode\u003ehist\u003c/code\u003e function are:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca href=\"https://www.tandfonline.com/doi/abs/10.1080/01621459.1926.10502161\"\u003eSturges'\nformula\u003c/a\u003e:\nThis method uses the following formula to determine the number of\nbins: k = 1 + log2(n), where k is the number of bins and n is the\nnumber of data points.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca href=\"https://link.springer.com/article/10.1007/BF01025868\"\u003eFreedman-Diaconis\nrule\u003c/a\u003e: This\nmethod uses the interquartile range (IQR) to determine the width of\neach bin. The formula for the bin width is: bin width = 2 * IQR /\n(n^(1/3)), where n is the number of data points.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca href=\"https://academic.oup.com/biomet/article-abstract/66/3/605/232642?redirectedFrom=fulltext\"\u003eScott's\nrule\u003c/a\u003e:\nThis method uses the standard deviation of the data to determine the\nwidth of each bin. The formula for the bin width is: bin width = 3.5\n* sd / (n^(1/3)), where sd is the standard deviation of the data\nand n is the number of data points.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eHere are some of the most commonly used arguments of \u003ccode\u003ehist()\u003c/code\u003efunction:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cem\u003ex: A vector of numeric values that specifies the data to be\nrepresented in the histogram.\u003c/em\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cem\u003ebreaks: A specification of the breakpoints (i.e., the edges of the\nbins) to use in the histogram. This can be a numeric vector, or a\nfunction such as breaks = \u0026quot;FD\u0026quot; to use the Freedman-Diaconis rule\nfor determining the bin widths.\u003c/em\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cem\u003efreq: A logical value that specifies whether the y-axis should\nrepresent the frequency (i.e., the count of values in each bin) or\nthe density (i.e., the proportion of values in each bin).\u003c/em\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cem\u003ecol: The color to use for the bars of the histogram.# border: The\ncolor to use for the borders of the bars of the histogram.\u003c/em\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cem\u003elwd: The line width to use for the borders of the bars of the\nhistogram.\u003c/em\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cem\u003edensity: A value between 0 and 1 specifying the density of shading\nlines for the bars of the histogram.\u003c/em\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cem\u003eangle: The angle in degrees of the shading lines for the bars of\nthe histogram.\u003c/em\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cem\u003eadd: A logical value that specifies whether the histogram should be\nadded to an existing plot.\u003c/em\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cem\u003eaxes: A logical value that specifies whether the axes should be\ndrawn for the histogram.\u003c/em\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cem\u003eplot: A logical value that specifies whether the histogram should\nbe plotted.\u003c/em\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cem\u003elabels: A logical value that specifies whether labels should be\nadded to the bars of the histogram.\u003c/em\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eHere how histogram looks like if I add some of the arguments:\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ehist(mpg,\n     breaks = \u0026#34;FD\u0026#34;, # for Freedman-Diaconis rule\n     freq = F,\n     ylim = c(0,0.08),\n     col = \u0026#34;burlywood4\u0026#34;,\n     border = \u0026#34;burlywood2\u0026#34;,\n     axes = F, labels = T)\n\u003c/code\u003e\u003c/pre\u003e\u003ch4 id=\"hist-with-a-low-level-functionlines\"\u003ehist() with a low-level function lines()\u003c/h4\u003e\n\u003cp\u003eWith the low-level function lines() it is possible to draw a density\nline in the histogram, which can give better information about the\ndistribution of the data.\u003c/p\u003e\n\u003cp\u003eLets simulate a data for this example:\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003eset.seed(1212)\nx \u0026lt;- rnorm(1000, 10, 4)\nx \u0026lt;- sort(x, decreasing = F)\nfun \u0026lt;- dnorm(x, mean = mean(x), sd = sd(x)) # calculating density\nhist(x, main = \u0026#34;histogram of x\u0026#34;, ylab = \u0026#34;Density\u0026#34;, xlab = \u0026#34;x\u0026#34;,col=\u0026#34;grey\u0026#34;,\n     border=\u0026#34;black\u0026#34;, probability = T, ylim = c(0, max(fun))) # drawing histogram with high-level function hist()\nlines(x,fun, col = 1, lwd = 2) # adding density line with low-level function lines()\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cimg src=\"https://cdn-images-1.medium.com/max/800/1*2iWMkV4_ec5clmNZabQ2xA.jpeg\" alt=\"\"\u003e\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003eHistograms have several advantages and disadvantages. Some of these\ninclude:\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eAdvantages:\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eHistograms are a useful tool for visualizing the distribution of a\ndataset. They provide a quick and easy way to see the range, shape,\nand central tendency of the data.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHistograms are flexible and can be used to visualize a wide range of\ndata types, including continuous, discrete, and categorical data.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHistograms can be used to identify outliers and unusual observations\nthat may be skewing the distribution of the data.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHistograms can be easily created in R and other statistical software\npackages, and can be customized with a variety of options, such as\nbin width, color, and labels.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eDisadvantages:\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eThe shape and appearance of a histogram can be sensitive to the\nchoice of bin width. Different bin widths can result in different\nvisualizations of the same data, which can make it difficult to\ncompare histograms.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHistograms can be sensitive to the choice of the number of bins. Too\nfew bins can result in a loss of information about the distribution,\nwhile too many bins can create a noisy and difficult-to-interpret\nhistogram.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHistograms can be misleading if the data are not properly\npreprocessed or if the data are not representative of the underlying\npopulation.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHistograms can be difficult to interpret for large datasets, or when\nthere is a high degree of variation in the data.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch3 id=\"boxplot\"\u003eBoxplot\u003c/h3\u003e\n\u003cp\u003eA boxplot is a graphical representation of the distribution of a\ndataset. It is a standardized way of displaying the distribution of data\nbased on five summary statistics: the minimum value, the first quartile\n(Q1), the median, the third quartile (Q3), and the maximum value.\u003c/p\u003e\n\u003cp\u003eHere are some of the most commonly used arguments of the\n\u003ccode\u003eboxplot()\u003c/code\u003efunction:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cem\u003eformula: a formula describing the variable(s) to be plotted.\u003c/em\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cem\u003edata: the data frame containing the variables to be plotted.\u003c/em\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cem\u003esubset: an optional vector specifying a subset of the data to be\nplotted.\u003c/em\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cem\u003ena.action: a function to handle missing data.\u003c/em\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cem\u003enames: a character vector giving the names of the variables to be\nplotted.\u003c/em\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cem\u003ehorizontal: a logical value indicating whether to plot the boxes\nhorizontally or vertically.\u003c/em\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cem\u003enotch: a logical value indicating whether to draw a notch around\nthe median of each box.\u003c/em\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cem\u003evarwidth: a logical value indicating whether the boxes should be\ndrawn with widths proportional to the square root of the number of\nobservations in each group.\u003c/em\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cem\u003eoutline: a logical value indicating whether to draw individual\npoints outside of the whiskers.\u003c/em\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cem\u003ecol: the color of the boxes, whiskers, and outliers.\u003c/em\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cem\u003eborder: the color of the border around the boxes.\u003c/em\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cem\u003eboxwex: the width of the boxes.\u003c/em\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cem\u003eat: a numeric vector giving the locations of the boxes along the\nx-axis.\u003c/em\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cem\u003eadd: a logical value indicating whether to add the boxplot to an\nexisting plot.\u003c/em\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eHere how basic boxplot looks like:\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003eboxplot(mpg)\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cimg src=\"https://cdn-images-1.medium.com/max/800/1*ILzF7cirNkR31OG29MPAbQ.jpeg\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003eHere how it looks like if I add some of the arguments to the function:\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003eboxplot(mpg, col = \u0026#34;chocolate\u0026#34;, \n        border = \u0026#34;khaki4\u0026#34;, \n        notch = T, \n        horizontal = T, \n        varwidth = T)\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cimg src=\"https://cdn-images-1.medium.com/max/800/1*ma8gKAFDPu0XvEn0m4x75Q.jpeg\" alt=\"\"\u003e\u003c/p\u003e\n\u003ch4 id=\"boxplot-with-a-low-level-function-text-abline\"\u003eboxplot() with a low-level function text() \u0026amp; abline()\u003c/h4\u003e\n\u003cp\u003eI will use \u003ccode\u003eiris\u003c/code\u003e dataset for this example. I will draw a line at the\nmean of Sepal Width using \u003ccode\u003eabline\u003c/code\u003e function. After, I will add /xbar to\nthe line.\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003eboxplot(iris$Sepal.Width~iris$Species, # group by species\n        main = \u0026#34;Sepal widths by species\u0026#34;,\n        col = c(\u0026#34;red\u0026#34;, \u0026#34;blue\u0026#34;, \u0026#34;gold\u0026#34;),\n        horizontal = T)\nabline(v = mean(iris$Sepal.Width), lty = 2) # adding horizontal line at the mean of sepal.width\ntext(3.1, 0.5, expression(bar(x))) # adding /xbar\n\u003c/code\u003e\u003c/pre\u003e\u003chr\u003e\n\u003cp\u003e\u003cstrong\u003eScatterplot\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eIn base R, it is possible to draw both line and scatterplot with the\nplot() function. A scatter plot is a type of graph that displays the\nrelationship between two continuous variables. Each point on the plot\nrepresents a single observation, with the x-axis representing the values\nof one variable and the y-axis representing the values of the other\nvariable. A line plot is a graph that displays data points connected by\nstraight lines. The x-axis represents the independent variable, and the\ny-axis represents the dependent variable.\u003c/p\u003e\n\u003cp\u003eHere is a basic scatterplot with plot() function:\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003eplot(mtcars$mpg, mtcars$hp)\n\u003c/code\u003e\u003c/pre\u003e\u003chr\u003e\n\u003cp\u003eScatter plots have several advantages and disadvantages. Some of these\ninclude:\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eAdvantages:\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eProvide a visual representation of the relationship between two\nvariables.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eShow the presence or absence of a relationship between the two\nvariables.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHelp in identifying outliers, trends, and patterns.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eProvide information about the direction and strength of the\nrelationship between the variables.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eDisadvantages:\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eCan only show the relationship between two variables.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eMay be difficult to interpret when there are a large number of\nobservations.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eMay not always show the true nature of the relationship between the\nvariables.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eCorrelation does not imply causation, and it is important to be\ncautious when interpreting the relationship shown in a scatter plot.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch3 id=\"line-plot\"\u003eLine Plot\u003c/h3\u003e\n\u003cp\u003eA line plot is a graph that displays data points connected by straight\nlines. # The x-axis represents the independent variable, and the y-axis\nrepresents the dependent variable. Here is a basic line plot with plot()\nfunction:\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003eplot(mpg, type = \u0026#34;l\u0026#34;)\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eLine plots have several advantages and disadvantages. Some of these\ninclude:\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eAdvantages:\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eCan show trends in data over time and provide insight into how the\ndata changes.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eCan also reveal patterns or fluctuations in the data that may not be\nimmediately apparent from a table of numbers.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eEasy to create and read, making them an effective way to communicate\ndata to a wide audience.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eCan be used to compare multiple sets of data on the same graph,\nallowing for easy visual comparison.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eDisadvantages:\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eMay not be appropriate for data that does not change over time.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eMay not be useful for showing data with a large number of categories\nor data points.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eCan be misleading if the data is not plotted accurately or if the\nscale of the graph is not appropriate.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eMay not be useful for identifying outliers or extreme values in the\ndata.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThe arguments for the \u003ccode\u003eplot()\u003c/code\u003efunction can vary depending on the type of\ngraph being created. Here are some common arguments for the the\nfunction:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cem\u003ex and y: the data to be plotted on the x-axis and y-axis,\nrespectively.\u003c/em\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cem\u003etype: the type of plot to be created. For example, \u0026quot;p\u0026quot; creates a\nscatter plot with points, \u0026quot;l\u0026quot; creates a line plot, \u0026quot;b\u0026quot; creates\nboth points and lines, and \u0026quot;h\u0026quot; creates a histogram.\u003c/em\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cem\u003emain: the main title of the plot.\u003c/em\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cem\u003exlab and ylab: the labels for the x-axis and y-axis, respectively.\u003c/em\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cem\u003exlim and ylim: limits for the x-axis and y-axis, respectively.\u003c/em\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cem\u003ecol: the color to be used for the points or lines\u003c/em\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cem\u003epch: type of symbol to be used for the points\u003c/em\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cem\u003elty: Type of line\u003c/em\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cem\u003ebty: type of box\u003c/em\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eHere how scatterplot looks like when I use these arguments:\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003eplot(mtcars$mpg, mtcars$hp,\n     main = \u0026#34;Title of the plot\u0026#34;,\n     xlab = \u0026#34;X axis\u0026#34;,\n     ylab = \u0026#34;Y axis\u0026#34;,\n     col = \u0026#34;chocolate\u0026#34;,\n     pch = \u0026#34;x\u0026#34;,\n     bty = \u0026#34;n\u0026#34;\n     )\n\u003c/code\u003e\u003c/pre\u003e\u003cpre tabindex=\"0\"\u003e\u003ccode\u003eplot(mpg, \n     type = \u0026#34;l\u0026#34;,\n     main = \u0026#34;Title of the plot\u0026#34;,\n     xlab = \u0026#34;X axis\u0026#34;,\n     ylab = \u0026#34;Y axis\u0026#34;,\n     col = \u0026#34;chocolate\u0026#34;,\n     lty = \u0026#34;dashed\u0026#34;,\n     bty = \u0026#34;L\u0026#34; \n     )\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cimg src=\"https://cdn-images-1.medium.com/max/800/1*MyA2giyjELoSA_RC8BI_7Q.jpeg\" alt=\"\"\u003e\u003c/p\u003e\n\u003ch4 id=\"plot-with-low-level-functionpoints\"\u003eplot() with low-level function points()\u003c/h4\u003e\n\u003cp\u003eFor this example, I will draw a partial function graph.\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ex1 \u0026lt;- seq(-2,-1.01, len = 100)\ny1 \u0026lt;- x1^2\nx2 \u0026lt;- seq(-1,1, len = 100)\ny2 \u0026lt;- rep(1, 100) \nx3 \u0026lt;- seq(1.01, 2, len = 100)\ny3 \u0026lt;- 2* x3 -1\n\nplot(x1,y1, xlim = c(-2,2), ylim = c(0,5), type = \u0026#34;l\u0026#34;, lwd = 3, col = \u0026#34;tomato2\u0026#34;, bty = \u0026#34;L\u0026#34;, xlab = \u0026#34;\u0026#34;, ylab = \u0026#34;\u0026#34;, main = \u0026#34;plot() \u0026amp; points()\u0026#34;)\npoints(x2,y2,type = \u0026#34;l\u0026#34;, lwd = 3, col = \u0026#34;chocolate4\u0026#34;)\npoints(x3,y3,type = \u0026#34;l\u0026#34;, lwd = 3, col = \u0026#34;lightsalmon\u0026#34;)\n\u003c/code\u003e\u003c/pre\u003e\u003ch4 id=\"plot-with-a-low-level-function-lines-andlegend\"\u003eplot() with a low-level function lines() and legend()\u003c/h4\u003e\n\u003cp\u003eFor this example, I will simulate chisquare distributed vectors with\ndifferent degrees of freedom.\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ex \u0026lt;- seq(0,60, len=1000)\n\ndf \u0026lt;- c(5,10,20,30) # setting degrees of freedom\ncolor \u0026lt;- c(\u0026#34;red\u0026#34;,\u0026#34;blue\u0026#34;, \u0026#34;green\u0026#34;,  \u0026#34;orange2\u0026#34;) # setting line colors\ntitle \u0026lt;- paste(\u0026#34;Chi-Square, df=\u0026#34;, df, sep = \u0026#34;\u0026#34; ) # setting titles\nline_type \u0026lt;- c(2,1,1,1) # setting line types\nline_width \u0026lt;- c(1,1,1,1) # setting line widths\n\nplot(x,xlim=c(0,60), ylim = c(0,0.15), main = \u0026#34;Different Chi-Square Distributions\u0026#34;, ylab=\u0026#34;Density\u0026#34;, type = \u0026#34;n\u0026#34;) # drawing empty plot\nfor (i in 1:length(df) ) { # for loop to draw line for each df\n  x \u0026lt;- seq(0,60, len=1000)\n  fx \u0026lt;- dchisq(x, df = df[i])\n  lines(x, fx, main = title[i], xlab = \u0026#34;x\u0026#34;, ylab =\u0026#34;Density\u0026#34;, col=color[i], lwd = line_width[i], lty = line_width[i])\n}\nlegend(\u0026#34;topright\u0026#34;, legend = title, col=color, lty = line_type) # legend to distinguish lines\n\u003c/code\u003e\u003c/pre\u003e\u003chr\u003e\n\u003ch3 id=\"par-function\"\u003e\u003cstrong\u003epar Function\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003eThe par() function is a built-in function in R that is used to set or\nretrieve graphical parameters. These parameters control the appearance\nof the graphics such as the size of the plotting region, the margins,\nthe axes, the color, and more. Here are some of the most common\narguments for the par() function:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cem\u003emfrow and mfcol: specify the number of rows and columns of plots to\nbe created on a page. mfrow creates plots in a matrix format,\nfilling rows first, while mfcol fills columns first.\u003c/em\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cem\u003emar: the margins of the plotting region in the form c(bottom, left,\ntop, right)\u003c/em\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cem\u003eoma: outer margins of the plotting region, i.e., the space between\nthe edge of the plotting region and the main title, axis labels, and\nso on, in the form c(bottom, left, top, right).\u003c/em\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cem\u003epty: the type of plot region to be used, either \u0026quot;s\u0026quot; (square) or\n\u0026quot;m\u0026quot; (maximal).\u003c/em\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cem\u003exaxs and yaxs: the style of the axis ranges. A value of \u0026quot;r\u0026quot;\n(default) indicates that the axis limits should be rounded to the\nnearest integer multiple of the tick interval, while a value of\n\u0026quot;i\u0026quot; indicates that the axis limits should be exactly at the data\nrange limits.\u003c/em\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cem\u003ecol: the color palette to be used for subsequent plots.\u003c/em\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cem\u003elty: the default line type to be used for subsequent plots.\u003c/em\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cem\u003elwd: the default line width to be used for subsequent plots.\u003c/em\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cem\u003ebg: background of the plot\u003c/em\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cem\u003ecex: the size of the text used for plot symbols and axis labels.\u003c/em\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cem\u003epch: the plotting character to be used for plot symbols.\u003c/em\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cem\u003elas: the orientation of axis labels. A value of 0 indicates\nhorizontal labels, while 1, 2, and 3 indicate labels perpendicular\nto the axis.\u003c/em\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cem\u003elog: whether the x- and/or y-axis should be plotted on a\nlogarithmic scale. A value of \u0026quot;x\u0026quot; indicates a logarithmic x-axis,\nwhile \u0026quot;y\u0026quot; indicates a logarithmic y-axis, and \u0026quot;xy\u0026quot; indicates a\nlogarithmic scale for both axes.\u003c/em\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cem\u003exlim and ylim: the limits of the x- and y-axis, respectively.\u003c/em\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cem\u003exaxt and yaxt: the style of the axis ticks. A value of \u0026quot;n\u0026quot;\nindicates that no axis should be drawn, while \u0026quot;s\u0026quot; indicates a\nsmall axis, \u0026quot;m\u0026quot; indicates a medium axis, and \u0026quot;l\u0026quot; indicates a\nlarge axis.\u003c/em\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eI will use the last example to show \u003ccode\u003epar\u003c/code\u003e function. However, line will\nnot be in the same graph this time.\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003epar(bg=\u0026#34;cornsilk\u0026#34;, \n    mfrow = c(2,2), \n    lwd = 4, \n    col = \u0026#34;burlywood4\u0026#34;, \n    pty=\u0026#34;m\u0026#34;, \n    oma = c(0,0,0,0)\n    )\n\nfor (i in 1:length(df) ) {\n  x \u0026lt;- seq(0,60, len=1000)\n  fx \u0026lt;- dchisq(x, df = df[i])\n  plot(x, fx, main = title[i], xlab = \u0026#34;x\u0026#34;, ylab =\u0026#34;Density\u0026#34;, col=color[i], type = \u0026#34;l\u0026#34; , lwd=2)\n}\n\u003c/code\u003e\u003c/pre\u003e\u003chr\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003eIMPORTANT NOTE:\u003c/strong\u003e The settings made with the par() function\npermanently change the graphics settings. For this reason, it is\nnecessary to reset the graphics settings after each use. For this, the\ndev.off() command can be used.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eJust like always:\u003c/p\u003e\n\u003cp\u003e\u0026quot;In case I don't see ya, good afternoon, good evening, and good\nnight!\u0026quot;\u003c/p\u003e\n\u003chr\u003e\n\u003ch3 id=\"useful-resources\"\u003eUseful Resources\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca href=\"https://r-graph-gallery.com/index.html\"\u003eR Graph Gallery\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca href=\"https://bookdown.org/aschmi11/RESMHandbook/data-visualization-in-base-r.html\"\u003eR Software\nHandbook\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca href=\"https://www.analyticsvidhya.com/blog/2015/07/guide-data-visualization-r/\"\u003eAnalytics\nVidhya\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca href=\"https://datacarpentry.org/R-genomics/05-data-visualization.html\"\u003eData\nCarpentry\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n","description":"","image":null,"permalink":"https://hugo-profile.netlify.app/blogs/dataviz/","title":"Data Visualization"},{"content":"\u003cp\u003eLiving is the art of dealing with as many problems as there are solutions. For this reason, as long as we are alive, we constantly have to struggle with a number of problems.\u003c/p\u003e\n\u003cp\u003eThere will always be problems, waiting to be solved. All we need to do is to try over and over again to overcome them. Just like Albert Einstein states:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cem\u003e\u0026ldquo;It\u0026rsquo;s not that I\u0026rsquo;m so smart, it\u0026rsquo;s just that I stay with problems longer.\u0026rdquo;\u003c/em\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eIn this article, I\u0026rsquo;m going to repeat the Infinite Monkey theorem using the R programming language, which I think can make you feel better when you think you are in a difficult situation.\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003eThe infinite monkey theorem is a hypothesis that states that an infinite number of monkeys, given an infinite amount of time and typewriters, would eventually produce the complete works of William Shakespeare or any other written text[1]. The idea behind the theorem is that given enough time and randomness, even highly improbable events can occur. The earliest known reference to the idea of monkeys typing at random comes from a 1913 essay by French mathematician Émile Borel, who used the concept to illustrate the concept of probability.\u003c/p\u003e\n\u003cp\u003eThe statistical proof of the theorem can be explained in a basic form as if two events are statistically independent (the events do not affect each other\u0026rsquo;s outcome), the probability of these two events occurring together is equal to the product of the probabilities of these events occurring separately.\u003c/p\u003e\n\u003cp\u003eIn fact, it can also be said that this theorem also points us to the Gambler\u0026rsquo;s Fallacy[2], a logical fallacy that many people fall victim to. To illustrate this fallacy, consider the classical coin toss experiment. Most people assume that because a coin has come up heads several times in a row, it\u0026rsquo;s more likely to come up tails in the next flip. However, it is absolutely impossible to know this for sure. After all, the probability for each independent flip is always 50%. Of course, this only applies if the coin is not cheated.\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003eNow, I am going to create a monkey to implement this theorem in R. This monkey is of course a function. Then I will try to randomly print some text to this monkey.\u003c/p\u003e\n\u003cp\u003eI think it is a good coding exercise to put some theorems, thought experiments, ideas into code. Thinking like a machine(algorithmic thinking) can be the most important component to turn the ideas in your mind into code. So, if you are faced with a task that you have never encountered before and you don\u0026rsquo;t know what to do, instead of struggling with writing the code, you can create a road map for yourself. This road map will actually \u0026ldquo;code\u0026rdquo; your coding skills. In this project, I will also show how I cope with this situation.\u003c/p\u003e\n\u003cp\u003eWhat do I need to do to code the infinite monkey theory?\u003c/p\u003e\n\u003cp\u003eOf course, I need the monkey! Lets create our monkey that randomly hits keys on a typewriter.\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003emonkey_the_author \u0026lt;- function(passage) {\n  chars \u0026lt;- c(letters, \u0026#34; \u0026#34;)\n  paste0(sample(chars, length(passage[1]), replace = TRUE), collapse = \u0026#34;\u0026#34;)\n}\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eAfter I have monkey, I need to do the experiment. Let\u0026rsquo;s start with a simple single word, monkey.\u003c/p\u003e\n\u003cp\u003eTo wrote this code, basically, I can say that I think in this way:\u003c/p\u003e\n\u003cp\u003e\u003cem\u003eI have a monkey that hits random keys. I\u0026rsquo;m going to ask this monkey to type a certain text, so I know the length of this text, I know the content of this text. When the monkey presses random keys, I have to make sure that the key it presses is the same as my target passage. And I have to keep doing this until the condition I want is met. So instead of for, I need to use a repeat loop. And the end of this loop is when the monkey reaches the final text.\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003eTo make it easy to understand, I wrote explanation about what each line does in code chunk!\u003c/p\u003e\n\u003chr\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003epassage1 \u0026lt;- (\u0026#34;monkey\u0026#34;)\n\ncount \u0026lt;- 0 # I want to know how many hits the monkey needed to write the passage.\nset.seed(123)\nrepeat { # I will use repeat loop because the loop has to continue until the condition I want is met.\n  count \u0026lt;- count + 1\n  test_passage \u0026lt;- rep(\u0026#34;\u0026#34;, length(passage1)) # vector to store the generated text.\n  for (i in 1:length(passage1)) { # iterate through each line \n    for (j in 1:nchar(passage1[[i]])) { # iterate through each character\n      test_char \u0026lt;- monkey_the_author(passage1) # monkey hits\n      # for each character, the loop generates random strings until a character that matches the corresponding character in the target text is found.\n      while (test_char != substr(passage1[[i]], j, j)) { # it uses the substr function to extract the character from the target text and compare it to the generated character.\n        test_char \u0026lt;- monkey_the_author(passage1) # if the generated character does not match the target character, the loop generates another random string and continues until a match is found\n        count \u0026lt;- count + 1 # to keep track of the number of attempts required\n      }\n      test_passage[i] \u0026lt;- paste0(test_passage[i], test_char) # Once a match is found, the loop concatenates the matched character to the current line\n    }\n  }\n  if (identical(test_passage, passage1)) { # If the entire test_passage vector matches the passage vector\n    break # the loop breaks\n  }\n}\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eExperiment is over. Now, let us check whether the entire test_passage matches the original passage.\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003etest_passage\n\n## [1] \u0026#34;monkey\u0026#34;\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eNow, let us see how many attempts required to generate the target passage. test_passage\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ecat(\u0026#34;It took\u0026#34;, count, \u0026#34;attempts to generate the target passage.\u0026#34;)\n\n## It took 148 attempts to generate the target passage.\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eEven though we succeeded with a low number of attempts, 148, what was the probability that a monkey pressing random keys would type this word correctly?\u003c/p\u003e\n\u003cp\u003eThe word \u0026ldquo;monkey\u0026rdquo; has 6 letters. At first, we need to determine the total number of possible ways to draw 6 letters from the 26 letters of the alphabet with replacement. Since we are drawing with replacement, each letter can be drawn more than once, so the number of ways to draw 6 letters from 26 with replacement is:\u003c/p\u003e\n\u003cp\u003e26⁶ = 26 x 26 x 26 x 26 x 26 x 26 = 308,915,776\u003c/p\u003e\n\u003cp\u003eThis means there are 308,915,776 possible 6-letter combinations that can be drawn with replacement from the alphabet.\u003c/p\u003e\n\u003cp\u003eTo calculate the probability of spelling \u0026ldquo;monkey\u0026rdquo;, we need to determine how many of these 6-letter combinations contain the letters \u0026ldquo;m\u0026rdquo;, \u0026ldquo;o\u0026rdquo;, \u0026ldquo;n\u0026rdquo;, \u0026ldquo;k\u0026rdquo;, \u0026ldquo;e\u0026rdquo;, and \u0026ldquo;y\u0026rdquo; in the correct order. Since each letter can be drawn with replacement, the probability of drawing any particular letter is 1/26.\u003c/p\u003e\n\u003cp\u003eTo calculate the probability of drawing all 6 letters in the correct order, we simply multiply the probability of drawing each letter:\u003c/p\u003e\n\u003cp\u003e(1/26) x (1/26) x (1/26) x (1/26) x (1/26) x (1/26) = 1/308,915,776\u003c/p\u003e\n\u003cp\u003eSo the probability of spelling \u0026ldquo;monkey\u0026rdquo; by randomly drawing 6 letters from the alphabet with replacement is approximately 1 in 308,915,776 or 0.000000324%. This is amazing!\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003eNow, let me repeat the experiment with a more complicated passage which is \u0026ldquo;monkey wrote this passage\u0026rdquo;. I run the code again by repeating the steps I did for the word \u0026ldquo;monkey\u0026rdquo;.\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003epassage2 \u0026lt;- (\u0026#34;monkey wrote this passage\u0026#34;)\n\n# again, the same processes\n\ncount2 \u0026lt;- 0\nset.seed(122)\nrepeat {\n  count2 \u0026lt;- count2 + 1\n  test_passage2 \u0026lt;- rep(\u0026#34;\u0026#34;, length(passage2))\n  for (i in 1:length(passage2)) {\n    for (j in 1:nchar(passage2[[i]])) {\n      test_char2 \u0026lt;- monkey_the_author(passage2)\n      while (test_char2 != substr(passage2[[i]], j, j)) {\n        test_char2 \u0026lt;- monkey_the_author(passage2)\n        count2 \u0026lt;- count2 + 1\n      }\n      test_passage2[i] \u0026lt;- paste0(test_passage2[i], test_char2)\n    }\n  }\n  if (identical(test_passage2, passage2)) {\n    break\n  }\n}\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eLet us check whether the entire test_passage matches the original passage.\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003etest_passage2\n\n## [1] \u0026#34;monkey wrote this passage\u0026#34;\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eLet us see how many attempts required to generate the target passage\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ecat(\u0026#34;It took\u0026#34;, count2, \u0026#34;attempts to generate the target passage.\u0026#34;)\n\n## It took 744 attempts to generate the target passage.\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eAgain, even though we succeeded with a relatively low number of attempts, 744, what was the probability that a monkey pressing random keys would type this word correctly?\u003c/p\u003e\n\u003cp\u003eThe sentence \u0026ldquo;monkey wrote this passage\u0026rdquo; has 23 letters. Thus, firstly, we first need to determine the total number of possible ways to draw 23 letters from the 26 letters of the alphabet with replacement. Since we are drawing with replacement, each letter can be drawn more than once, so the number of ways to draw 23 letters from 26 with replacement is:\u003c/p\u003e\n\u003cp\u003e26²³ = 351,843,720,888,320,000,000,000,000\u003c/p\u003e\n\u003cp\u003eThis means there are 351,843,720,888,320,000,000,000,000 possible 23-letter combinations that can be drawn with replacement from the alphabet.\u003c/p\u003e\n\u003cp\u003eTo calculate the probability of spelling \u0026ldquo;monkey wrote this passage\u0026rdquo;, we need to determine how many of these 23-letter combinations contain the letters in the correct order. Since each letter can be drawn with replacement, the probability of drawing any particular letter is 1/26.\u003c/p\u003e\n\u003cp\u003eTo calculate the probability of drawing all 23 letters in the correct order, we simply multiply the probability of drawing each letter:\u003c/p\u003e\n\u003cp\u003e(1/26)²³ = 1/817,0728068870529046\u0026hellip; × 10²³\u003c/p\u003e\n\u003cp\u003eSo the probability of spelling \u0026ldquo;monkey wrote this passage\u0026rdquo; by randomly drawing 23 letters from the alphabet with replacement(hang on to your hat!) is approximately 1 in 8.170728068870529046\u0026hellip; × 10²³ or 0.0000000000000000000000000000000000000000865% !!!!!\u003c/p\u003e\n\u003cp\u003eNot surprisingly, As the number of words in the passage that the monkeys are asked to write increases, the number of iterations in the loop, i.e. the number of attemps required, will also increase. This inevitable relationship is actually the basis of the theorem. Aside from the astonishment of realizing such low probabilities, however, it is also possible to interpret this theorem from another perspective. For example, it took 148 attempts for monkeys to type the word \u003ccode\u003emonkey\u003c/code\u003e by pressing random keys. What would happen if I used a for loop instead of repeat and iterated the loop 147 times?\u003c/p\u003e\n\u003cp\u003eYes, sometimes a certain number of iterations will be enough to achieve the goal. But the thing to never forget is the real key to success: keep going until the condition is met! \u003ccode\u003eRepeat\u003c/code\u003edoing what you need to do to get what you want, until you get what you want! If you are struggling to achieve something you want to achieve and you can\u0026rsquo;t get it even after countless attempts, you either don\u0026rsquo;t have enough time or you don\u0026rsquo;t have enough resources. Keep trying, get the resources you need (try a \u003ccode\u003erepeat\u003c/code\u003eloop instead of a \u003ccode\u003efor\u003c/code\u003eloop), and eventually you will succeed!\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eIf you have enough time and resources, you can perform an event with a probability of 0.0000000000000000000000000000000000000000000000000000000000000000865%.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eLet\u0026rsquo;s end this project with the output of the code whose input I have hidden. Let\u0026rsquo;s see what the monkey wrote for us[3] this time.\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e## i am the master of my fate \n##  i am the captain of my soul\n\u003c/code\u003e\u003c/pre\u003e\u003chr\u003e\n\u003cp\u003e\u003cstrong\u003eReadings\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e[1] Crowley, John. \u0026ldquo;The Million Monkeys of M. Borel.\u0026rdquo; Conjunctions 67 (2016): 57\u0026ndash;60.\u003c/p\u003e\n\u003cp\u003e[2] \u003ca href=\"https://yourlogicalfallacyis.com/the-gamblers-fallacy\"\u003ehttps://yourlogicalfallacyis.com/the-gamblers-fallacy\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e[3] \u003ca href=\"https://www.poetryfoundation.org/poems/51642/invictus\"\u003ehttps://www.poetryfoundation.org/poems/51642/invictus\u003c/a\u003e\u003c/p\u003e\n","description":null,"image":null,"permalink":"https://hugo-profile.netlify.app/blogs/infmonkey/","title":"Infinite Monkey"},{"content":"\u003chr\u003e\n\u003cp\u003eI plan to write many series of articles in my medium journey that I started with \u003ca href=\"https://medium.com/@ozturkfemre/data-visualization-with-base-r-a3d6d4e2acdc\"\u003edata visualization\u003c/a\u003e. In addition to series such as Unsupervised Statistical Learning, Supervised Statistical Learning, Math for Data Science, Statistics and Probability, I will also touch on the intersection of my undergraduate degree in philosophy and data science. In this way, I think I can support analytical and critical thinking for the individual who is on a data science journey. I will also have some articles that I plan to combine culture and data science.\u003c/p\u003e\n\u003cp\u003eIn this regard, I am with you with the first post of the first series, Unsupervised Statistical Learning. In this post, I will talk about the methods to determine the optimal number of clusters. In this post, as in every other post, I will talk about what methods mean, what they are used for and how to do it step by step. I will run all methods in R by using the k-means clustering algorithm and always use the same dataset (\u003ca href=\"https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+%28diagnostic%29\"\u003eBreast Cancer Wisconsin\u003c/a\u003e).\u003c/p\u003e\n\u003chr\u003e\n\u003ch3 id=\"why-do-we-need-to-determine-clusternumber\"\u003eWhy do we need to determine cluster number?\u003c/h3\u003e\n\u003cp\u003eThe first reason is that the number of clusters must be predetermined for the clustering algorithms to work. For example, many algorithms such as k-means, k-medoids, hierarchical clustering need to know the number of clusters in order to work. Depending on the data set and the work done with that data set, we may know the number of clusters in advance. For example, in the plot below, it is quite possible to determine the number of clusters with a scatter plot.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://cdn-images-1.medium.com/max/800/1*b218oEdOwrx8g24HC13B5w.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003eHowever, determining the number of clusters in commonly encountered data sets is too complex to be achieved simply by observing the overall structure of the data set with a scatter plot. For example, when the scatter plot below is analyzed, it is not possible to tell how many clusters the data set is divided into.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://cdn-images-1.medium.com/max/800/1*ekHDzQi6HseK6uGd6yv0Zg.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003eHowever, since situations like the one in the above plot are frequently encountered, some methods have been proposed to determine the number of clusters. I will now explain what some of these methods are, how they are calculated step by step and their implementation in R.\u003c/p\u003e\n\u003chr\u003e\n\u003ch3 id=\"elbow-method\"\u003eElbow Method\u003c/h3\u003e\n\u003cp\u003eThe elbow method, also known as \u003cem\u003etotal within sum of squares\u003c/em\u003e, is a technique used to determine the optimal number of clusters for a k-means clustering analysis. The idea behind the elbow method is to run k-means clustering on the dataset for a range of values of k (number of clusters), and for each value of k calculate the sum of squared distances of each point from its closest centroid (SSE). The elbow point is the point on the plot of SSE against the number of clusters (k) where the change in SSE begins to level off, indicating that adding more clusters doesn't improve the model much. [1], [2]\u003c/p\u003e\n\u003cp\u003eThe steps to perform the elbow method are:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003eSelect a range of k values, usually from 1 to 10 or the square root of the number of observations in the dataset.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eRun k-means clustering for each k value and calculate the SSE (sum of squared distances of each point from its closest centroid).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003ePlot the SSE for each k value.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe point on the plot where the SSE starts to decrease at a slower rate is the elbow point, and the corresponding number of clusters is the optimal value for k.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eUndoubtedly, the Elbow method is one of the most widely used methods. It can be said to be a method that follows the same logic as k-means. However, it would not be correct to say that it gives good results under all circumstances. Sometimes it can even be said to be misleading. For this reason, although I use the elbow method in every cluster analysis, I do not rely on it alone.\u003c/p\u003e\n\u003cp\u003eIn R, \u003ccode\u003efactoextra\u003c/code\u003e packages offers fancy plots for some of the methods to determine optimal number of clusters in this post. I will use \u003ccode\u003efviz_nbclust\u003c/code\u003e function to visualize elbow method for the dataset.\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003efviz_nbclust(df, # data  \n             kmeans, # clustering algorithm \n             nstart = 25, # if centers is a number, how many random sets should be chosen?(default is 25)\n             iter.max = 200, # the maximum number of iterations allowed.\n             method = \u0026#34;wss\u0026#34;) # elbow method\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cimg src=\"https://cdn-images-1.medium.com/max/800/1*v5FiIzpDhJAHEE7DmosoOA.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003eFor example, the output above shows that there is no sharp elbow. For this reason, it draws attention as a result open to interpretation. An interpretation based on this elbow may therefore lead to incorrect results.\u003c/p\u003e\n\u003chr\u003e\n\u003ch3 id=\"average-silhouette-method\"\u003eAverage Silhouette Method\u003c/h3\u003e\n\u003cp\u003eAverage silhouette method measures how well-defined a particular cluster is, and how well-separated it is from other clusters. At this point, it is necessary to state that Silhouette value is calculated for each observation in the data set. Average of the silhouette value of all observations gives us the average silhouette value, which is the silhouette value of the clustering analysis [3] , [4].\u003c/p\u003e\n\u003cp\u003eThe steps to calculate silhouette value for a observation are:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003ecalculate cluster tightness: the average distance purple observation to all blue observations which all are in the same cluster, which is called a(i).\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://cdn-images-1.medium.com/max/800/1*oPJ8x71lbkMomHRx4qm2Ug.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e2. calculate cluster separation: observation's minimum distance to all the observations in a different cluster(yellow cluster), which is called b(i).\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://cdn-images-1.medium.com/max/800/1*h0Ues0gLRs2FD5TrOpmFGA.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e3. calculate silhouette coefficient: calculate its silhouette value \u0026quot;s(i)\u0026quot; as the difference between the b(i) and a(i), divided by the maximum of these two distances:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://cdn-images-1.medium.com/max/800/1*L2nNHjwqpS7ZOdXZEvTC2g.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003eAfter calculating silhouette coefficient of each observation, we can finally, calculate the average silhouette value for all observations: mean(si). To determine the number of clusters, we usually cluster each number of clusters for a range of 2 to 10 clusters and obtain the average silhouette value for each number of clusters. The silhouette value ranges from -1 to 1, where a value of 1 indicates a strong similarity to the other observations in its own cluster, and a value of -1 indicates a strong similarity to observations in another cluster. In other words, the number of clusters with the highest silhouette value is the number of clusters we will determine.\u003c/p\u003e\n\u003cp\u003eAgain \u003ccode\u003efviz_nbclust\u003c/code\u003e function is a way to see average silhoutte plot to decide the optimal number of clusters:\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003efviz_nbclust(df, # data\n             kmeans, # clustering algorithm\n             method = \u0026#34;silhouette\u0026#34;) # silhouette\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cimg src=\"https://cdn-images-1.medium.com/max/800/1*yxQGOAUuwKUAT66scEaWWg.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003eAs can be easily seen from the plot, the clustering model with the highest silhouette value is the clustering for 2 clusters. Therefore, it can be inferred that the optimal number of clusters is two. However, when the silhouette values on the y-axis are examined, the silhouette value for the number of clusters 3 is also quite close, although the number of clusters 2 is the highest. For this reason, it would be more useful to always run the clustering algorithm for both 2 and 3 clusters and interpret the results.\u003c/p\u003e\n\u003chr\u003e\n\u003ch3 id=\"gap-statistic-method\"\u003eGap Statistic Method\u003c/h3\u003e\n\u003cp\u003eGap Statistic Method compares the observed within-cluster variation for different values of k with the variation expected under a null reference distribution of the data. [5]\u003c/p\u003e\n\u003cp\u003eThe steps to perform the gap statistic method are:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003eSelect a range of k values, usually from 1 to 10 or the square root of the number of observations in the dataset.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eRun the clustering algorithm (such as k-means or hierarchical clustering) for each k value and calculate the within-cluster variation Wk.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eGenerate B reference datasets by randomly sampling the original data and calculate the within-cluster variation W*k for each dataset.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eCalculate the gap statistic\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003ePlot the gap statistic for each k value.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe k value that corresponds to the maximum gap statistic is the optimal number of clusters.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eAgain \u003ccode\u003efviz_nbclust\u003c/code\u003e function is a way to see gap statistic plot to decide the optimal number of clusters:\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003efviz_nbclust(df, \n             kmeans ,\n             nstart = 25, \n             method = \u0026#34;gap_stat\u0026#34;)\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cimg src=\"https://cdn-images-1.medium.com/max/800/1*mqekOsPoqAI2qWdSylkhrA.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003eJust like Average Silhouette Method, Gap Statistic Method is also offers 2 as the optimal number of clusters.\u003c/p\u003e\n\u003chr\u003e\n\u003ch3 id=\"calinski---harabaszmethod\"\u003eCalinski \u0026mdash; Harabasz Method\u003c/h3\u003e\n\u003cp\u003eThe Calinski-Harabasz index (also known as the Variance Ratio Criterion) is a commonly used evaluation metric for comparing different clustering solutions in unsupervised learning. It is a ratio of the between-cluster variance and the within-cluster variance, and it is used to determine the number of clusters that should be used in a clustering solution[6].\u003c/p\u003e\n\u003cp\u003eThe steps to perform the calinski-harabasz method are:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003ecalculate within cluster sum of squares (WCSS): the sum of the squared distances between each observation and its corresponding cluster center(barycenter).\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://cdn-images-1.medium.com/max/800/1*4WNGuodDuuGJE_rCGrQwLw.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e2. calculate between cluster sum of squares (BCSS): calculate the sum of the squared distances between each cluster center and the overall mean of all the observation.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://cdn-images-1.medium.com/max/800/1*aeLLLdSZe-juNaQIm2irbQ.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e3. (BCSS / WCSS) \u0026mdash; (n-k) / (k-1)\u003c/p\u003e\n\u003cp\u003ewhere,\u003c/p\u003e\n\u003cp\u003ek: total cluster number,\u003c/p\u003e\n\u003cp\u003en:total observation number\u003c/p\u003e\n\u003cp\u003eThe Calinski-Harabasz index ranges from 0 to infinity, with a higher value indicating a better clustering.\u003c/p\u003e\n\u003cp\u003eFor the Calinski \u0026mdash; Harabasz method, there is no visualization function in R as in the methods I mentioned before. For this reason, I will write a function that calculates and visualizes the Calinski \u0026mdash; Harabasz values for the clusters 2 to 10 using the \u003ccode\u003ecalinhara\u003c/code\u003e function in the \u003ccode\u003efpc\u003c/code\u003e package.\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003elibrary(fpc) # for calinhara function\n\nfviz_ch \u0026lt;- function(data) {\n  ch \u0026lt;- c()\n  for (i in 2:10) {\n    km \u0026lt;- kmeans(data, i) # perform clustering\n    ch[i] \u0026lt;- calinhara(data, # data\n                       km$cluster, # cluster assignments\n                       cn=max(km$cluster) # total cluster number\n                       )\n  }\n  ch \u0026lt;-ch[2:10]\n  k \u0026lt;- 2:10\n  plot(k, ch,xlab =  \u0026#34;Cluster number k\u0026#34;,\n       ylab = \u0026#34;Caliński - Harabasz Score\u0026#34;,\n       main = \u0026#34;Caliński - Harabasz Plot\u0026#34;, cex.main=1,\n       col = \u0026#34;dodgerblue1\u0026#34;, cex = 0.9 ,\n       lty=1 , type=\u0026#34;o\u0026#34; , lwd=1, pch=4,\n       bty = \u0026#34;l\u0026#34;,\n       las = 1, cex.axis = 0.8, tcl  = -0.2)\n  abline(v=which(ch==max(ch)) + 1, lwd=1, col=\u0026#34;red\u0026#34;, lty=\u0026#34;dashed\u0026#34;)\n}\n\nfviz_ch(df)\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cimg src=\"https://cdn-images-1.medium.com/max/800/1*rmXp5yUexMVNx6L_5Mg6DA.jpeg\" alt=\"\"\u003e\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003eAs the other methods, Calinski \u0026mdash; Harabasz methods is also offered 2 clusters for the dataset.\u003c/p\u003e\n\u003chr\u003e\n\u003ch3 id=\"davies---bouldinmethod\"\u003eDavies \u0026mdash; Bouldin Method\u003c/h3\u003e\n\u003cp\u003eThe Davies-Bouldin index (DBI) is a measure of the similarity between the clusters in a clustering solution. The DBI is calculated as the average similarity between each cluster and its most similar cluster, where the similarity between two clusters is defined as the maximum distance between any observation in one cluster and its closest observation in the other cluster. [7]\u003c/p\u003e\n\u003cp\u003eThe steps to performDBI are:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003ecalculate intra-cluster dispersion: the average distance of all the data points in each cluster to the cluster center.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://cdn-images-1.medium.com/max/800/1*aeLLLdSZe-juNaQIm2irbQ.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003ecalculate separation criteria: the Euclidean distance between the cluster centers for each pair of clusters.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://cdn-images-1.medium.com/max/800/1*HtFg6se9Yzdt8jE5zRnLmw.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e3. find the most similar cluster: for each pair of clusters, calculate the similarity d(i, j) between the two clusters, as defined in the previous answer. Sum up the maximum similarity between each cluster and its most similar cluster. Divide the sum by the number of clusters to obtain the Davies-Bouldin index.\u003c/p\u003e\n\u003cp\u003eThe Davies-Bouldin index ranges from 0 to infinity, with a lower value indicating a better clustering solution. A DBI of 0 indicates that there is no similarity between any two clusters, while a high DBI value indicates that there is a high level of similarity between some of the clusters.\u003c/p\u003e\n\u003cp\u003eJust like the Calinski-Harabasz method, there is no visualization function in R as for Davies-Bouldin method. For this reason, I will write a function that calculates and visualizes the Davies \u0026mdash; Bouldin value for the clusters 2 to 10 using the \u003ccode\u003eNbClust\u003c/code\u003e function in the \u003ccode\u003eNbClust\u003c/code\u003e package.\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003elibrary(NbClust)\n\nfviz_db \u0026lt;- function(data) {\n  k \u0026lt;- c(2:10)\n  nb \u0026lt;- NbClust(data, min.nc = 2, max.nc = 10, index = \u0026#34;db\u0026#34;, method = \u0026#34;kmeans\u0026#34;)\n  db \u0026lt;- as.vector(nb$All.index)\n  plot(k, db,xlab =  \u0026#34;Cluster number k\u0026#34;,\n       ylab = \u0026#34;Davies-Bouldin Score\u0026#34;,\n       main = \u0026#34;Davies-Bouldin Plot\u0026#34;, cex.main=1,\n       col = \u0026#34;dodgerblue1\u0026#34;, cex = 0.9 ,\n       lty=1 , type=\u0026#34;o\u0026#34; , lwd=1, pch=4,\n       bty = \u0026#34;l\u0026#34;,\n       las = 1, cex.axis = 0.8, tcl  = -0.2)\n  abline(v=which(db==min(db)) + 1, lwd=1, col=\u0026#34;red\u0026#34;, lty=\u0026#34;dashed\u0026#34;)\n}\n\n\nfviz_db(df)\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cimg src=\"https://cdn-images-1.medium.com/max/800/1*JyF0ay_whg6ohuhv1w2pDg.jpeg\" alt=\"\"\u003e\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003eUnlike other methods, we see that Davies-Bouldin's suggestion for the number of clusters is 7. Although it gives different results in this data set, it can give more reliable results in other data sets. For this reason, it would be useful to include the Davies-Bouldin method in every clustering analysis.\u003c/p\u003e\n\u003chr\u003e\n\u003ch3 id=\"dunn-index\"\u003eDunn Index\u003c/h3\u003e\n\u003cp\u003eThe Dunn index is a measure of the compactness and separability of the clusters in a clustering solution. It is calculated as the ratio of the minimum separation to the maximum diameter. [8]\u003c/p\u003e\n\u003cp\u003eThe steps to perform Dunn Index are:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003ecalculate minimum separation: the smallest distance between the observations from two different clusters.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://cdn-images-1.medium.com/max/800/1*EHsIVbk6_82UuuxrKn602Q.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e2. calculate maximum diameter: the maximum distance between the observations in the same cluster.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://cdn-images-1.medium.com/max/800/1*Fl9-NiLKg17SXiz71CMHDw.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e3. divide minimum separation by maximum diameter\u003c/p\u003e\n\u003cp\u003eThe Dunn index ranges from 0 to infinity, with a higher value indicating a better clustering solution. A value of 1 indicates that the clusters are perfectly separated and perfectly compact, while a low value indicates that the clusters are either not separated or not compact.\u003c/p\u003e\n\u003cp\u003eJust like Calinski-Harabasz and Davies- Bouldin methods, there is no visualization function in R as for Dunn Index. For this reason, I will write a function that calculates and visualizes the Dunn Index values for the clusters 2 to 10 using the \u003ccode\u003edunn\u003c/code\u003e function in the \u003ccode\u003eclValid\u003c/code\u003e package.\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003elibrary(clValid)\n\nfviz_dunn \u0026lt;- function(data) {\n  k \u0026lt;- c(2:10)\n  dunnin \u0026lt;- c()\n  for (i in 2:10) {\n    dunnin[i] \u0026lt;- dunn(distance = dist(data), clusters = kmeans(data, i)$cluster)\n  }\n  dunnin \u0026lt;- dunnin[2:10]\n  plot(k, dunnin, xlab =  \u0026#34;Cluster number k\u0026#34;,\n       ylab = \u0026#34;Dunn Index\u0026#34;,\n       main = \u0026#34;Dunn Plot\u0026#34;, cex.main=1,\n       col = \u0026#34;dodgerblue1\u0026#34;, cex = 0.9 ,\n       lty=1 , type=\u0026#34;o\u0026#34; , lwd=1, pch=4,\n       bty = \u0026#34;l\u0026#34;,\n       las = 1, cex.axis = 0.8, tcl  = -0.2)\n  abline(v=which(dunnin==max(dunnin)) + 1, lwd=1, col=\u0026#34;red\u0026#34;, lty=\u0026#34;dashed\u0026#34;)\n}\n\nfviz_dunn(df)\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cimg src=\"https://cdn-images-1.medium.com/max/800/1*nB0iTIEA1mnhuiCZHIyecw.jpeg\" alt=\"\"\u003e\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003eAs the Davies-Bouldin methods, Dunn also suggested different cluster number. As I said before, each method may give different results for each data set. For this reason, it is useful to compare all methods in each clustering analysis.\u003c/p\u003e\n\u003cp\u003eJust like always:\u003c/p\u003e\n\u003cp\u003e\u0026quot;In case I don't see ya, good afternoon, good evening, and good night!\u0026quot;\u003c/p\u003e\n\u003chr\u003e\n\u003ch4 id=\"references\"\u003eReferences\u003c/h4\u003e\n\u003cp\u003e[1] Steinley, D., \u0026amp; Brusco, M. J. (2011). Choosing the number of clusters in Κ-means clustering. Psychological methods, 16(3), 285.\u003c/p\u003e\n\u003cp\u003e[2] Halkidi, Maria, Yannis Batistakis, and Michalis Vazirgiannis. \u0026quot;On clustering validation techniques.\u0026quot; Journal of intelligent information systems 17 (2001): 107\u0026ndash;145.\u003c/p\u003e\n\u003cp\u003e[3] Rousseeuw, Peter J. Silhouettes: a graphical aid to the interpretation and validation of cluster analysis.Journal of computational and applied mathematics, 1987, 20: 53\u0026ndash;65.\u003c/p\u003e\n\u003cp\u003e[4] Halkidi, M., Batistakis, Y., \u0026amp; Vazirgiannis, M. (2001). On clustering validation techniques. Journal of intelligent information systems, 17, 107\u0026ndash;145.\u003c/p\u003e\n\u003cp\u003e[5] Tibshirani, R., Walther, G., \u0026amp; Hastie, T. (2001). Estimating the number of clusters in a data set via the gap statistic. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 63(2), 411\u0026ndash;423.\u003c/p\u003e\n\u003cp\u003e[6] Caliński, T., \u0026amp; Harabasz, J. (1974). A dendrite method for cluster analysis. Communications in Statistics-theory and Methods, 3(1), 1\u0026ndash;27.\u003c/p\u003e\n\u003cp\u003e[7] Davies, D. L., \u0026amp; Bouldin, D. W. (1979). A cluster separation measure. IEEE transactions on pattern analysis and machine intelligence, (2), 224\u0026ndash;227.\u003c/p\u003e\n\u003cp\u003e[8] Dunn, J. C. (1973). A fuzzy relative of the ISODATA process and its use in detecting compact well-separated clusters.\u003c/p\u003e\n","description":null,"image":null,"permalink":"https://hugo-profile.netlify.app/blogs/optimalk/","title":"Unsupervised Learning in R | Determination of Cluster Number"}]